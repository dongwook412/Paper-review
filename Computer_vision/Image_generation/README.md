# Super-Resolution
## 1. SRGAN
Ledig, C., Theis, L., HuszÃ¡r, F., Caballero, J., Cunningham, A., Acosta, A., ... & Wang, Z. (2016). Photo-realistic single image super-resolution using a generative adversarial network. arXiv preprint 2016.

### ìš”ì•½
- Super Resolution(SR, í™”ì§ˆ ê°œì„  ë° ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¦ê°€) ì•Œê³ ë¦¬ì¦˜
- ê¸°ì¡´ SR ì•Œê³ ë¦¬ì¦˜ì€ lossë¥¼ (pixel-wise)MSEê³¼ PSNRë¡œ êµ¬ì„± &#8594; ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì§ˆê°(texture) í‘œí˜„ì— í•œê³„(smoothí•˜ê²Œë§Œ í‘œí˜„)
- lossë¥¼ ê°œì„ í•˜ì—¬ ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ì˜ í•œê³„ ê·¹ë³µ &#8594; Perceptual loss function(Content loss + Adversarial loss)

### Method
#### (1) Architecture
- GAN  
<img src = "./img/srgan/architecture.PNG" width="50%"></center>

#### (2) Loss function
- Perceptual loss function  
<img src = "./img/srgan/loss1.PNG"></center>

- Content loss  

  ì´ë¯¸ì§€ ìì²´(pixel)ë¥¼ ë¹„êµí•˜ë˜ ê¸°ì¡´ lossë¥¼ feature mapì„ ë¹„êµí•˜ëŠ” lossë¡œ ë³€ê²½  
  
  __ê¸°ì¡´ì˜ pixel-wise MSE loss__  
  <img src = "./img/srgan/loss2.PNG"></center>

  __ìˆ˜ì •ëœ loss(Content loss)__  
  <img src = "./img/srgan/loss3.jpg" width="50%"></center>

- Advrsarial loss  
<img src = "./img/srgan/loss4.PNG"></center>  

## 2. EDSR
Lim, B., Son, S., Kim, H., Nah, S., & Mu Lee, K. (2017). Enhanced deep residual networks for single image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops (pp. 136-144).

### ìš”ì•½
- ResNet êµ¬ì¡°ì—ì„œ í•„ìš”í•˜ì§€ ì•Šì€ ëª¨ë“ˆì„ ì œê±°í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì„(EDSR)
- ì—¬ëŸ¬ scaleì— ê³µí†µìœ¼ë¡œ í¬í•¨ë˜ëŠ” ì •ë³´ë¥¼ ê³µìœ í•˜ëŠ” ìƒˆë¡œìš´ multi-scale êµ¬ì¡°ë¥¼ ì œì•ˆ(MDSR)
- MDSRì€ ì—¬ëŸ¬ ê°œì˜ Scale ëª¨ë¸ì— ë¹„í•´ ì ì€ ìˆ˜ì˜ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©°, ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì„

### Method
#### (1) EDSR Architecture
- Batch Normalization(BN) ì œê±°

  BNormalizationì€ íŠ¹ì • ë²”ìœ„ë¡œ ì •ê·œí™”ë¥¼ í•˜ëŠ” ì—­í• ì„ í•˜ë¯€ë¡œ ê¸°ì¡´ì˜ Classificaton & Detection ë¬¸ì œì™€ ë‹¤ë¥´ê²Œ ì œê±°í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ &#8594; GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì—¬ ê²°ê³¼ì ìœ¼ë¡œ ë” í° ëª¨ë¸ ì œì‘ì´ ê°€ëŠ¥
  
<img src = "./img/edsr/Comparsion_residual_block.PNG" width="50%"></center>
- í•´ìƒë„ ë³„(x2, x3, x4) ë„¤íŠ¸ì›Œí¬ ê°œë³„ í•™ìŠµ: í•´ìƒë„ ë³„ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ëŠ” Upsamplingì„ ì œì™¸í•˜ê³  ëª¨ë‘ ê°™ìŒ & Upsamplingì˜ ê²½ìš° SRGANê³¼ ë™ì¼í•˜ê²Œ Shuffleì„ ì‚¬ìš©í•˜ë©° í•™ìŠµ ê°€ëŠ¥

<img src = "./img/edsr/Architecture(EDSR).PNG" width="50%"></center>
- Residual scalingì„ ì ìš©í•˜ì—¬ Feature mapì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë ¤ ë” ë§ì€ ì •ë³´ë¥¼ í•™ìŠµ
- x2 scaleì— ëŒ€í•œ ì‚¬ì „ í•™ìŠµëœ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ x3, x4 scaleì„ í•™ìŠµ &#8594; ë” ë¹ ë¥¸ ìˆ˜ë ´ ê°€ëŠ¥
  
#### (2) MDSR Architecture
- Scale-specific processing module : ë„¤íŠ¸ì›Œí¬ ì•ì— ìœ„ì¹˜. ë‹¤ì–‘í•œ scaleì˜ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ ë¶„ì‚°ì„ ì¤„ì´ëŠ” ì—­í• 
- Scale-specific upsampling module : ë„¤íŠ¸ì›Œí¬ ë’¤ì— ìœ„ì¹˜. ë‹¤ì–‘í•œ scaleì— ëŒ€í•´ upsamplingí•´ì£¼ëŠ” ì—­í• ë¡œ EDSRì˜ êµ¬ì¡°ì™€ ìœ ì‚¬
- ì¤‘ì•™ì˜ ResBlocksë¥¼ ê³µìœ  &#8594; EDSR 3ê°œì˜ íŒŒë¼ë¯¸í„°ë³´ë‹¤ ë” ì ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©
<img src = "./img/edsr/Architecture(MDSR).PNG" width="50%"></center>

## 3. ESRGAN
Wang, X., Yu, K., Wu, S., Gu, J., Liu, Y., Dong, C., ... & Change Loy, C. (2018). Esrgan: Enhanced super-resolution generative adversarial networks. In Proceedings of the European Conference on Computer Vision (ECCV) Workshops (pp. 0-0).

### ìš”ì•½
- SRGANì—ì„œ 3ê°€ì§€ ë¶€ë¶„(Architecture, Discriminator, Perceptual loss) ê°œì„   

### Method  
#### (1) Architecture(Generator)  
- Batch Normalization(BN) ì œê±° & Residual scaling ë„ì… 
 
  BNì€ í›ˆë ¨ ì¤‘ì— batchì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©í•˜ì—¬ featureë¥¼ normalizeí•˜ê³  í…ŒìŠ¤íŠ¸ ì¤‘ì— ì „ì²´ í•™ìŠµ ë°ì´í„°ì˜ ì¶”ì •ëœ í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©. í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í†µê³„ê°’ì´ ë§ì´ ë‹¤ë¥¼ ë•Œ BN ê³„ì¸µì€ unpleasant artifactë¥¼ ë„ì…í•˜ê³  ì¼ë°˜í™” ëŠ¥ë ¥ ì œí•œ &#8594; BN ë ˆì´ì–´ë¥¼ ì œê±°í•˜ì—¬ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê³  ê³„ì‚° ë³µì¡ì„±ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì„   
  residualì„ 0ê³¼ 1ì‚¬ì´ì˜ ìƒìˆ˜ë¥¼ ê³±í•˜ì—¬ scaling downí•˜ëŠ” Residual scalingë¥¼ ë„ì…í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¦
- Residual-in-Residual Dense Block(RDDB) ë„ì… &#8594; higher capacity & easier to train  
<img src = "./img/esrgan/architecture1.PNG" width="50%"></center>  
<img src = "./img/esrgan/architecture2.PNG" width="50%"></center>  

#### (2) Discriminator  
- Relativistic GAN(RaGAN) ì‚¬ìš©: ê¸°ì¡´ GANì˜ DiscriminatorëŠ” realì¸ì§€ fakeì¸ì§€ íŒë‹¨í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ì˜€ë‹¤ë©´ RaGANì˜ DiscriminatorëŠ” í•œ ì´ë¯¸ì§€ê°€ ë‹¤ë¥¸ ì´ë¯¸ì§€ë³´ë‹¤ ë” ì‹¤ì œ ê°™ì€ì§€ë¥¼ íŒë‹¨ &#8594; more realistic texture details  
  __Standard Discriminator & Relativistic Discriminator__  
<img src = "./img/esrgan/discriminator.PNG" width="50%"></center>  
  __Discriminator loss__  
<img src = "./img/esrgan/discriminator_loss.PNG" width="50%"></center>  
  __Generator loss__  
<img src = "./img/esrgan/generator_loss.PNG" width="50%"></center>  
<img src = "./img/esrgan/E.PNG" width="3%"></center>ëŠ” ì‹¤ì œ ë°ì´í„°(X<sub>r</sub>) í•œ ê°œì— ëŒ€í•´ ìƒì„±ëœ ì´ë¯¸ì§€(X<sub>f</sub>)ëŠ” ì—¬ëŸ¬ ê°œì´ë¯€ë¡œ, ëª¨ë“  mini-batchì˜ fake dataì— ëŒ€í•´ average ì·¨í•¨  
  SRGANì—ì„œëŠ” Generator lossê°€ ìƒì„±ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ ì˜í–¥ì„ ë°›ì§€ë§Œ ESRGANì—ì„œëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ìƒì„±ëœ ë°ì´í„° ëª¨ë‘ë¡œë¶€í„° ì˜í–¥ ë°›ìŒ  
#### (3) Perceptual loss ê°œì„   
- activation ì´ì „ì˜ VGG feature ì‚¬ìš©(SRGANì—ì„œëŠ” activation ì´í›„ì˜ feature ì‚¬ìš©) &#8594; sharper edges & more visually pleasing results  
- activationì„ ì·¨í•œ featureëŠ” Sparseí•´ì§„ë‹¤ëŠ” ë¬¸ì œ ì¡´ì¬(íŠ¹íˆ Very deep networkì¼ ê²½ìš° ë”ìš± ì‹¬í•¨) &#8594; weak supervision & inferior performance(ì•„ë˜ ê·¸ë¦¼ì—ì„œ after activationì„ ë³´ë©´ featureê°€ ë§ì´ ì‚¬ë¼ì§ì„ ì•Œ ìˆ˜ ìˆìŒ)    
<img src = "./img/esrgan/feature_map.PNG" width="60%"></center>  
  __Total loss for the Generator__  
<img src = "./img/esrgan/L_G.PNG" width="20%"></center>  
  __L<sub>1</sub> loss(Content loss)__  
<img src = "./img/esrgan/L_1.PNG" width="20%"></center>  
  L<sub>G</sub>ëŠ” Total Generator lossì´ë©° L<sub>percep</sub>ì™€ L<sub>G</sub><sup>Ra</sup>(Relativistic Discriminatorì—ì„œì˜ Generator loss), L<sub>1</sub>ë¡œ ì´ë£¨ì–´ì§  
  L<sub>1</sub>ì€ content lossë¡œ G(x<sub>i</sub>)ì™€ ground-truth yì™€ì˜ 1-norm distanceì— í•´ë‹¹í•¨  
#### (4) Network Interpolation  
- G<sub>PSNR</sub>(PSNR-oriented network) í•™ìŠµ &#8594; fine-tuningí•´ì„œ G<sub>GAN</sub>(GAN-based network) í•™ìŠµ
- ë‘ ëª¨ë¸(G<sub>PSNR</sub>, G<sub>GAN</sub>)ì„ ë³´ê°„í•˜ì—¬ G<sub>INTERP</sub> ëª¨ë¸ ë„ì¶œ  
<img src = "./img/esrgan/network_interpolation.PNG" width="40%"></center>  

### ì ìš© ê²°ê³¼  
<img src = "./img/esrgan/comparison.PNG" width="50%"></center>  

## 4. EDVR
Wang, X., Chan, K. C., Yu, K., Dong, C., & Change Loy, C. (2019). Edvr: Video restoration with enhanced deformable convolutional networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (pp. 0-0).

### ìš”ì•½
- PCD(Pyramid, Cascading and Deformable) & TSA(Temporal and Spatial Attention) ëª¨ë“ˆì„ ì‚¬ìš©
- PCDëŠ” Deformable convolutionì„ ì‚¬ìš©í•˜ì—¬ feature ìˆ˜ì¤€ì—ì„œ coarse-to-fine ë°©ì‹ìœ¼ë¡œ frameì´ alignmentë¨
- TSAëŠ” ì—¬ëŸ¬ alignëœ featureì—ì„œ ì¤‘ìš” ì •ë³´ë¥¼ ì‹œê³µê°„ì ìœ¼ë¡œ attentioní•˜ì—¬ fusion

### Method
#### (1) Architecture
- PCDì™€ TSA ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ í¬ê³  ë‹¤ì–‘í•œ ë™ì‘ ë° Blur í˜„ìƒì´ ìˆëŠ” frameë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬
- Fusionëœ featureë¥¼ Reconstruction ëª¨ë“ˆì— ëŒ€ì…í•˜ê³  Upsamplingí•œ ê²°ê³¼ì™€, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ Upsamplingí•œ ê²°ê³¼ë¥¼ ë”í•˜ì—¬ ìµœì¢… Output ì¶œë ¥
<img src = "./img/edvr/architecture.PNG" width="90%"></center> 
  
#### (2) PCD Module
- (ë¹¨ê°„ìƒ‰ ë°•ìŠ¤): L1 -> L2 -> L3

  ğ‘¡ì‹œì ê³¼ ì¸ì ‘í•œ ğ‘¡+ğ‘–ì‹œì ì˜ ì´ë¯¸ì§€ëŠ” ì—¬ëŸ¬ ê°œì˜ Residual Blockì„ ì§€ë‚˜ Feature ì¶”ì¶œ(L1)
  ì¶”ì¶œëœ Featureë“¤ì— Strided Convolutionì„ ì´ìš©í•˜ì—¬ x2 Downsampling ìˆ˜í–‰í•˜ë©°(L2), í•œë²ˆ ë” ìˆ˜í–‰í•˜ë©´ L3ì— ëŒ€í•œ Featureë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ



#### (3) TSA Module
